{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import MDS\n",
    "import seaborn as sns\n",
    "\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils import CIFAR\n",
    "from src.model import CIFAR_CNN\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_sampling(model, optimizer, train_loader, criterion, device, ckpt_folder):\n",
    "    model.train()\n",
    "    os.makedirs(ckpt_folder, exist_ok=True)\n",
    "    \n",
    "    for i, (images, labels) in enumerate(tqdm(train_loader, desc=\"Computing gradient differences\")):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        gradient = {name: param.grad.clone() for name, param in model.named_parameters()}\n",
    "        \n",
    "        torch.save(gradient, os.path.join(ckpt_folder, f'gradients_{i}.pt'))\n",
    "        \n",
    "def evaluate_sgd_update(model, gradient, lr, test_loader, criterion, device):\n",
    "    model_copy = torch.nn.Module()  # Создаем копию модели\n",
    "    model_copy.load_state_dict(model.state_dict())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for name, param in model_copy.named_parameters():\n",
    "            if name in gradient:\n",
    "                param -= lr * gradient[name]\n",
    "    \n",
    "    model_copy.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_copy(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(test_loader)\n",
    "\n",
    "def compute_gradient_distances(ckpt_folder):\n",
    "    gradient_files = sorted(f for f in os.listdir(ckpt_folder) if f.startswith(\"gradients_\") and f.endswith(\".pt\"))\n",
    "    distance_dict = {}\n",
    "    \n",
    "    for name in torch.load(os.path.join(ckpt_folder, gradient_files[0])).keys():\n",
    "        distance_dict[name] = torch.zeros((len(gradient_files), len(gradient_files)))\n",
    "    \n",
    "    for i in tqdm(range(len(gradient_files)), desc=f\"Processing gradients (i)\"):\n",
    "        gradient_i = torch.load(os.path.join(ckpt_folder, gradient_files[i]))\n",
    "        \n",
    "        for j in tqdm(range(i + 1, len(gradient_files)), desc=f\"Processing gradients (j) for i={i}\", leave=False):\n",
    "            gradient_j = torch.load(os.path.join(ckpt_folder, gradient_files[j]))\n",
    "            \n",
    "            for name in gradient_i:\n",
    "                cos_sim = F.cosine_similarity(gradient_i[name].flatten(), gradient_j[name].flatten(), dim=0)\n",
    "                distance = 1 - cos_sim.item()\n",
    "                distance_dict[name][i, j] = distance\n",
    "                distance_dict[name][j, i] = distance  # Симметричное заполнение\n",
    "    return distance_dict\n",
    "\n",
    "def visualize_mds(distance_matrix):\n",
    "    mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n",
    "    coords = mds.fit_transform(distance_matrix)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(coords[:, 0], coords[:, 1], c='blue', label='Gradients')\n",
    "    \n",
    "    for i, (x, y) in enumerate(coords):\n",
    "        plt.text(x, y, str(i), fontsize=9, ha='right')\n",
    "    \n",
    "    plt.xlabel(\"MDS Component 1\")\n",
    "    plt.ylabel(\"MDS Component 2\")\n",
    "    plt.title(\"MDS Visualization of Gradient Distances\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def extract_gradients(ckpt_folder, flattened = True):\n",
    "    gradient_files = sorted(f for f in os.listdir(ckpt_folder) if f.startswith(\"gradients_\") and f.endswith(\".pt\"))\n",
    "    gradients = {}\n",
    "    \n",
    "    for i, file in enumerate(tqdm(gradient_files, desc=\"Loading gradients\")):\n",
    "        gradient = torch.load(os.path.join(ckpt_folder, file))\n",
    "        \n",
    "        for name, tensor in gradient.items():\n",
    "            if name not in gradients:\n",
    "                gradients[name] = []\n",
    "            \n",
    "            gradients[name].append(tensor.flatten().cpu().detach().numpy() if flattened else tensor.cpu().detach().numpy())\n",
    "            \n",
    "    return gradients\n",
    "\n",
    "def visualize_mds_from_gradients(gradient_vectors):\n",
    "    gradient_matrix = torch.stack(gradient_vectors).cpu().numpy()  # Перемещение на CPU\n",
    "    mds = MDS(n_components=2, dissimilarity='euclidean', random_state=42)\n",
    "    coords = mds.fit_transform(gradient_matrix)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(coords[:, 0], coords[:, 1], c='blue', label='Gradients')\n",
    "    \n",
    "    for i, (x, y) in enumerate(coords):\n",
    "        plt.text(x, y, str(i), fontsize=9, ha='right')\n",
    "    \n",
    "    plt.xlabel(\"MDS Component 1\")\n",
    "    plt.ylabel(\"MDS Component 2\")\n",
    "    plt.title(\"MDS Visualization of Gradient Vectors\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"mps\"\n",
    "\n",
    "# Папка с чекпоинтами\n",
    "CHECKPOINT_MODELS = f\"{repo_root}/data/checkpoints/exp6\"\n",
    "CHECKPOINT_DIR = f\"{repo_root}/data/checkpoints/exp9\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "checkpoint_path = os.path.join(CHECKPOINT_MODELS, \"model_seed_0_epoch_20.pth\")\n",
    "model = CIFAR_CNN().to(DEVICE)\n",
    "model.load_state_dict(torch.load(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing gradient differences: 100%|██████████| 100/100 [00:03<00:00, 26.13it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "train_dataset, test_dataset, train_loader, test_loader = CIFAR(batch_size=batch_size, sample_size=800)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "stochastic_gradient_sampling(model, optimizer, train_loader, criterion, DEVICE, ckpt_folder=CHECKPOINT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gradients (i): 100%|██████████| 100/100 [01:31<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "distances = compute_gradient_distances(ckpt_folder=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading gradients: 100%|██████████| 100/100 [00:01<00:00, 95.30it/s]\n"
     ]
    }
   ],
   "source": [
    "gradients = extract_gradients(ckpt_folder=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1.weight',\n",
       " 'conv1.bias',\n",
       " 'conv2.weight',\n",
       " 'conv2.bias',\n",
       " 'conv3.weight',\n",
       " 'conv3.bias',\n",
       " 'conv4.weight',\n",
       " 'conv4.bias',\n",
       " 'conv5.weight',\n",
       " 'conv5.bias',\n",
       " 'conv6.weight',\n",
       " 'conv6.bias',\n",
       " 'bn64.weight',\n",
       " 'bn64.bias',\n",
       " 'bn128.weight',\n",
       " 'bn128.bias',\n",
       " 'bn256.weight',\n",
       " 'bn256.bias',\n",
       " 'bn512.weight',\n",
       " 'bn512.bias',\n",
       " 'fc.weight',\n",
       " 'fc.bias']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(gradients.keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for key in keys:\n",
    "#     visualize_mds_from_gradients(gradients[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading gradients: 100%|██████████| 100/100 [00:01<00:00, 52.67it/s]\n"
     ]
    }
   ],
   "source": [
    "gradients = extract_gradients(ckpt_folder=CHECKPOINT_DIR, flattened=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mplt\u001b[49m.figure(figsize=(\u001b[32m10\u001b[39m,\u001b[32m4\u001b[39m) )\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m,\u001b[32m32\u001b[39m):\n\u001b[32m      4\u001b[39m     weight = np.mean(gradients[\u001b[33m'\u001b[39m\u001b[33mfc.weight\u001b[39m\u001b[33m'\u001b[39m][:m] , axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4) )\n",
    "\n",
    "for m in range(1,32):\n",
    "    weight = np.mean(gradients['fc.weight'][:m] , axis=0)\n",
    "    \n",
    "    # weight = weight * ( weight**2 > 1e-3)\n",
    "    \n",
    "    plt.plot(weight.reshape(-1)[:1000] , label = f'{m}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4) )\n",
    "\n",
    "for m in range(1,10):\n",
    "    weight = np.sum(gradients['fc.weight'][:m] , axis=0)\n",
    "    \n",
    "    # weight = weight * ( weight**2 > 1e-3)\n",
    "    \n",
    "    plt.plot(weight.reshape(-1)[:1000] , label = f'{m}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## а что если на больших батчах юзать loss(reduction = 'sum' ) вместо loss(reduciton = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

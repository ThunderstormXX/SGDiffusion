# Эксперимент 17: SGD vs GD с отслеживанием гессианов

## Описание
Эксперимент 17 основан на эксперименте 16 с улучшениями для более детального анализа поведения оптимизаторов SGD и GD на плато.

## Ключевые улучшения по сравнению с экспериментом 16:

### 1. Увеличенный размер выборки
- **Было**: 386 образцов
- **Стало**: 1000 образцов
- **Цель**: Получить больше ненулевых собственных значений гессиана

### 2. Отслеживание валидационных метрик
- Train Loss (каждую эпоху)
- Validation Loss (каждые 100 эпох при обучении, каждые 50 шагов при отслеживании гессианов)
- Validation Accuracy (каждые 100 эпох при обучении, каждые 50 шагов при отслеживании гессианов)

### 3. Сравнение оптимизаторов
- **SGD**: Стохастический градиентный спуск с батчами
- **GD**: Полный градиентный спуск (весь датасет как один батч)

### 4. Конфигурация экспериментов
- **Learning rates**: 0.1, 0.01 (1e-1, 1e-2)
- **Batch size**: 64
- **Максимальные эпохи**: 60,000
- **Шаги после плато**: 500
- **Device**: Настраивается через аргументы командной строки

### 5. Детальное отслеживание прогресса
- Информативные progress bars с метриками в реальном времени
- Отслеживание улучшений валидационных метрик
- Статистика собственных значений гессианов
- Визуализация изменений метрик

## Структура файлов

### Скрипты
- `exp17_train_to_plateau.py` - Обучение модели до плато
- `exp17_continue_and_log.py` - Продолжение обучения с отслеживанием гессианов
- `exp17_runner.py` - Автоматический запуск всех экспериментов
- `run_exp17.sh` - Bash скрипт для удобного запуска

### Результаты (в `data/checkpoints/exp17/`)
- `plateau_model_{optimizer}_lr{lr}.pth` - Обученные модели
- `plateau_metadata_{optimizer}_lr{lr}.npy` - Метаданные обучения
- `params_tensor_{optimizer}_lr{lr}.pkl` - Траектории параметров
- `hessians_tensor_{optimizer}_lr{lr}.pkl` - Гессианы на каждом шаге
- `metadata_{optimizer}_lr{lr}.pkl` - Метаданные отслеживания
- `progress_{optimizer}_lr{lr}.png` - Графики прогресса обучения
- `final_{optimizer}_lr{lr}.png` - Финальные графики

## Запуск экспериментов

### Автоматический запуск всех экспериментов
```bash
# Автоматический выбор устройства (GPU если доступно, иначе CPU)
./run_exp17.sh

# Принудительное использование GPU
./run_exp17.sh cuda

# Принудительное использование CPU
./run_exp17.sh cpu

# Конкретный GPU
./run_exp17.sh --device=3
./run_exp17.sh 2

# Или напрямую через Python
python exp17_runner.py [device]
```

### Ручной запуск отдельных экспериментов
```bash
# Обучение с lr=0.01 на GPU
python exp17_train_to_plateau.py --lr 0.01 --batch-size 64 --device cuda

# Отслеживание гессианов для lr=0.01 на CPU
python exp17_continue_and_log.py --lr 0.01 --batch-size 64 --device cpu

# Конкретный GPU
python exp17_train_to_plateau.py --lr 0.1 --batch-size 64 --device 3
```

### Параметры устройства:
- `auto` (по умолчанию) - автоматический выбор (CUDA если доступно)
- `cuda` - принудительное использование GPU
- `cpu` - принудительное использование CPU
- `0`, `1`, `2`, `3`... - конкретный GPU по индексу

## Отслеживаемые метрики

### Во время обучения до плато:
- **Train Loss**: Потери на обучающей выборке
- **Val Loss**: Потери на валидационной выборке
- **Val Accuracy**: Точность на валидационной выборке
- **Best Val Loss**: Лучшая валидационная потеря
- **Epochs without improvement**: Эпохи без улучшения

### Во время отслеживания гессианов:
- **Train Loss**: Потери на текущем батче
- **Val Loss**: Валидационные потери
- **Val Accuracy**: Валидационная точность
- **ΔVal Loss**: Изменение валидационной потери
- **ΔVal Acc**: Изменение валидационной точности
- **Max Eigenvalue**: Максимальное собственное значение гессиана
- **Condition Number**: Число обусловленности гессиана

## Ожидаемые результаты

### Всего экспериментов: 8
- 2 learning rates × 2 optimizers × 2 этапа = 8 задач

### Файлы результатов:
- 4 обученные модели (SGD/GD × lr 0.1/0.01)
- 4 набора траекторий параметров
- 4 набора гессианов
- 8 файлов метаданных
- Графики прогресса и финальные визуализации

## Анализ результатов

После завершения экспериментов можно анализировать:

1. **Сравнение траекторий**: Как SGD и GD ведут себя на плато
2. **Собственные значения**: Спектр гессианов для разных оптимизаторов
3. **Влияние learning rate**: Как lr влияет на поведение на плато
4. **Валидационные метрики**: Обобщающая способность моделей
5. **Стабильность обновлений**: Анализ шума в градиентах

## Концептуальные отличия от эксперимента 16

1. **Больше данных**: 1000 vs 386 образцов → больше ненулевых собственных значений
2. **Валидация**: Отслеживание качества обобщения
3. **Два оптимизатора**: Прямое сравнение SGD vs GD
4. **Детальный мониторинг**: Расширенная статистика в реальном времени
5. **Автоматизация**: Полностью автоматизированный pipeline

Эксперимент позволяет получить более полную картину поведения оптимизаторов на плато и их влияния на спектр гессиана.
# Эксперимент 17: SGD vs GD с отслеживанием гессианов

## Описание
Эксперимент 17 основан на эксперименте 16 с улучшениями для более детального анализа поведения оптимизаторов SGD и GD на плато.

## Ключевые улучшения по сравнению с экспериментом 16:

### 1. Увеличенный размер выборки
- **Было**: 386 образцов
- **Стало**: 1000 образцов
- **Цель**: Получить больше ненулевых собственных значений гессиана

### 2. Отслеживание валидационных метрик
- Train Loss (каждую эпоху)
- Validation Loss (каждые 100 эпох при обучении, каждые 50 шагов при отслеживании гессианов)
- Validation Accuracy (каждые 100 эпох при обучении, каждые 50 шагов при отслеживании гессианов)

### 3. Сравнение оптимизаторов
- **SGD**: Стохастический градиентный спуск с батчами
- **GD**: Полный градиентный спуск (весь датасет как один батч)

### 4. Конфигурация экспериментов
- **Learning rates**: 0.1, 0.01 (1e-1, 1e-2)
- **Batch size**: 64
- **Максимальные эпохи**: 60,000
- **Шаги после плато**: 500

### 5. Детальное отслеживание прогресса
- Информативные progress bars с метриками в реальном времени
- Отслеживание улучшений валидационных метрик
- Статистика собственных значений гессианов
- Визуализация изменений метрик

## Структура файлов

### Скрипты
- `exp17_train_to_plateau.py` - Обучение модели до плато
- `exp17_continue_and_log.py` - Продолжение обучения с отслеживанием гессианов
- `exp17_runner.py` - Автоматический запуск всех экспериментов
- `run_exp17.sh` - Bash скрипт для удобного запуска

### Результаты (в `data/checkpoints/exp17/`)
- `plateau_model_{optimizer}_lr{lr}.pth` - Обученные модели
- `plateau_metadata_{optimizer}_lr{lr}.npy` - Метаданные обучения
- `params_tensor_{optimizer}_lr{lr}.pkl` - Траектории параметров
- `hessians_tensor_{optimizer}_lr{lr}.pkl` - Гессианы на каждом шаге
- `metadata_{optimizer}_lr{lr}.pkl` - Метаданные отслеживания
- `progress_{optimizer}_lr{lr}.png` - Графики прогресса обучения
- `final_{optimizer}_lr{lr}.png` - Финальные графики

## Запуск экспериментов

### Автоматический запуск всех экспериментов
```bash
# Через bash скрипт
./run_exp17.sh

# Или напрямую через Python
python exp17_runner.py
```

### Ручной запуск отдельных экспериментов
```bash
# Обучение SGD с lr=0.01
python exp17_train_to_plateau.py --lr 0.01 --optimizer sgd --batch-size 64

# Отслеживание гессианов для SGD с lr=0.01
python exp17_continue_and_log.py --lr 0.01 --optimizer sgd --batch-size 64

# Обучение GD с lr=0.1
python exp17_train_to_plateau.py --lr 0.1 --optimizer gd --batch-size 64

# Отслеживание гессианов для GD с lr=0.1
python exp17_continue_and_log.py --lr 0.1 --optimizer gd --batch-size 64
```

## Отслеживаемые метрики

### Во время обучения до плато:
- **Train Loss**: Потери на обучающей выборке
- **Val Loss**: Потери на валидационной выборке
- **Val Accuracy**: Точность на валидационной выборке
- **Best Val Loss**: Лучшая валидационная потеря
- **Epochs without improvement**: Эпохи без улучшения

### Во время отслеживания гессианов:
- **Train Loss**: Потери на текущем батче
- **Val Loss**: Валидационные потери
- **Val Accuracy**: Валидационная точность
- **ΔVal Loss**: Изменение валидационной потери
- **ΔVal Acc**: Изменение валидационной точности
- **Max Eigenvalue**: Максимальное собственное значение гессиана
- **Condition Number**: Число обусловленности гессиана

## Ожидаемые результаты

### Всего экспериментов: 8
- 2 learning rates × 2 optimizers × 2 этапа = 8 задач

### Файлы результатов:
- 4 обученные модели (SGD/GD × lr 0.1/0.01)
- 4 набора траекторий параметров
- 4 набора гессианов
- 8 файлов метаданных
- Графики прогресса и финальные визуализации

## Анализ результатов

После завершения экспериментов можно анализировать:

1. **Сравнение траекторий**: Как SGD и GD ведут себя на плато
2. **Собственные значения**: Спектр гессианов для разных оптимизаторов
3. **Влияние learning rate**: Как lr влияет на поведение на плато
4. **Валидационные метрики**: Обобщающая способность моделей
5. **Стабильность обновлений**: Анализ шума в градиентах

## Концептуальные отличия от эксперимента 16

1. **Больше данных**: 1000 vs 386 образцов → больше ненулевых собственных значений
2. **Валидация**: Отслеживание качества обобщения
3. **Два оптимизатора**: Прямое сравнение SGD vs GD
4. **Детальный мониторинг**: Расширенная статистика в реальном времени
5. **Автоматизация**: Полностью автоматизированный pipeline

Эксперимент позволяет получить более полную картину поведения оптимизаторов на плато и их влияния на спектр гессиана.